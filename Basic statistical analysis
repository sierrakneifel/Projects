{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMt5r1OoT0nMcioSgcilyaP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sierrakneifel/Projects/blob/main/IN502_Week_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scale and MinMaxScaler"
      ],
      "metadata": {
        "id": "_8X_LYr2lnnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing #Import the necessary modules\n",
        "\n",
        "hmeq = pd.read_csv('hmeq_small.csv') #Read in the file hmeq_small.csv\n",
        "\n",
        "#Standardize the data\n",
        "standardized = preprocessing.scale(hmeq) # Code to standardize the data\n",
        "\n",
        "# Output the standardized data as a data frame\n",
        "df1 = pd.DataFrame(standardized, columns = [\"LOAN\", \"MORTDUE\", \"VALUE\", \"YOJ\", \"CLAGE\", \"CLNO\", \"DEBTINC\"]) # Code to output as a data frame\n",
        "\n",
        "# Normalize the data\n",
        "normalized = preprocessing.MinMaxScaler().fit_transform(hmeq) # Code to normalize the data\n",
        "\n",
        "# Output the standardized data as a data frame\n",
        "df2 = pd.DataFrame(normalized, columns = [\"LOAN\", \"MORTDUE\", \"VALUE\", \"YOJ\", \"CLAGE\", \"CLNO\", \"DEBTINC\"])# Code to ouput as a data frame\n",
        "\n",
        "# Print the means and standard deviations of df1 and df2\n",
        "print(\"The means of df1 are \", df1.mean()) # Code for mean of df1\n",
        "print(\"The standard deviations of df1 are \", df1.std())  # Code for standard deviation of df1\n",
        "print(\"The means of df2 are \", df2.mean()) # Code for mean of df2\n",
        "print(\"The standard deviations of df2 are \", df2.std()) # Code for standard deviation of df2"
      ],
      "metadata": {
        "id": "D70aJsowlrsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop and Fill NA"
      ],
      "metadata": {
        "id": "PHPJcf2TluVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Import the necessary modules\n",
        "\n",
        "hmeq = pd.read_csv('hmeq_small.csv') # Code to read in hmeq_small.csv\n",
        "\n",
        "# Create a new data frame with the rows with missing values dropped\n",
        "df1 = hmeq.dropna() # Code to delete rows with missing values\n",
        "\n",
        "# Create a new data frame with the missing values filled in by the mean of the column\n",
        "df2 = hmeq.fillna(hmeq.mean()) # Code to fill in missing values\n",
        "\n",
        "# Print the means of the columns for each new data frame\n",
        "print(\"Means for df1 are \", df1.mean())\n",
        "\n",
        "print(\"Means for df2 are \", df2.mean())"
      ],
      "metadata": {
        "id": "O7xcI5cklws1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chi-Square Test"
      ],
      "metadata": {
        "id": "UnRqdDYll20d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as st\n",
        "from scipy import stats\n",
        "from scipy.stats import chi2_contingency # Import the necessary modules\n",
        "\n",
        "women = np.array([[580,1019],[289,169],[503,178],[618,208],[742,1148]])# Construct a contingency table\n",
        "\n",
        "\n",
        "# Calculate the test statistic and p-value\n",
        "chi2, p, df, ex = chi2_contingency(women) # Code for calculating test statistic and p-value\n",
        "print(chi2)\n",
        "print(p)\n",
        "\n",
        "# Determine if null hypothesis is rejected or not\n",
        "if p < 0.01:\n",
        "    print(\"The hypothesis that tea and coffee are drunk with the same frequency is rejected.\")\n",
        "else:\n",
        "    print(\"The hypothesis that tea and coffee are drunk with the same frequency is not rejected.\")"
      ],
      "metadata": {
        "id": "vlQmdZWhl5XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confidence Intervals for Population Means"
      ],
      "metadata": {
        "id": "zxjhwh_Kl8Lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as st\n",
        "import numpy as np # import the necessary modules\n",
        "\n",
        "# Get user defined mean and standard deviation\n",
        "mean_def = int(input())\n",
        "sd_def = int(input())\n",
        "\n",
        "np.random.seed(seed=123)\n",
        "\n",
        "# Generate 100 random numbers with a normal distribution with a mean of mean_def and a standard deviation of sd_def\n",
        "r = st.norm.rvs(mean_def, sd_def, size=100)\n",
        "\n",
        "# Calculate the sample mean of r\n",
        "mean = r.mean() # Code for calculating mean\n",
        "print(\"Sample mean is\", mean)\n",
        "\n",
        "# Calculate the standard error of r\n",
        "std_dev = r.std() # Code for calculating standard deviation of r\n",
        "stderr = std_dev/np.sqrt(100)  # Code for calculating standard error\n",
        "\n",
        "# Calculate the 95% confidence interval using the sample mean and standard error\n",
        "int1 = st.norm.interval(0.95,mean,stderr) #Code for confidence interval\n",
        "print(int1)\n",
        "\n",
        "# Determine if the user defined mean falls within the 95% confidence interval\n",
        "if mean_def > int1[0]: # Finish the if statement\n",
        "    if mean_def < int1[1]:\n",
        "        print(\"User defined mean,\", mean_def,\", is within the 95% confidence interval\")\n",
        "else:\n",
        "   print(\"User defined mean,\", mean_def,\", is not within the 95% confidence interval\")"
      ],
      "metadata": {
        "id": "ae0wU0_wl_qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confidence Intervals for Population Proportions"
      ],
      "metadata": {
        "id": "k16_394BmBkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import scipy.stats as st\n",
        "import numpy as np # Import necessary modules\n",
        "\n",
        "age = int(input())\n",
        "\n",
        "titanic = pd.read_csv('titanic.csv') # Read csv file titanic.csv into data frame\n",
        "#titanic = titanic.dropna()\n",
        "\n",
        "# Take the subset of the data where Embarked = \"S\"\n",
        "south = titanic[titanic.Embarked == \"S\"]# Code to take subset\n",
        "\n",
        "# Find total number in subset\n",
        "n1 = south['Embarked'].count() # Code to count number in subset\n",
        "\n",
        "# Find number in subset where Age > age\n",
        "x1 = south[south[\"Age\"] > age]['Age'].count() # Code to count number where Age > age\n",
        "\n",
        "#print(x1)\n",
        "# Calculate proportion\n",
        "p1 = x1/n1 # Code to calculate proportion\n",
        "print(\"Sample proportion is\", p1)\n",
        "\n",
        "std_dev = south['Age'].std() # Calculate standard error\n",
        "#stderr = std_dev/np.sqrt(n1) # Code to calculate standard error\n",
        "stderr = (p1*(1-p1)/n1) ** 0.5\n",
        "\n",
        "# Find 95% confidence interval\n",
        "#mean = south['Age'].mean()\n",
        "conf_int = st.norm.interval(0.95, p1, stderr) # Code to find confidence interval\n",
        "print(conf_int)\n",
        "\n",
        "# Find proportion for full data\n",
        "n2 = len(titanic.index) # Code to count number in data set\n",
        "#n2 = titanic['Embarked'].count() # Code to count number in data set\n",
        "#x2 = titanic[titanic['Age']>age]['age'].count() #Code to count number in full data set where Age > age\n",
        "x2 = titanic[titanic[\"Age\"]>age]['Age'].count()\n",
        "#x2 = titanic[[\"Age\" > age]].count()\n",
        "p2 = x2/n2 # Code to calculate proportion\n",
        "#print(p2)\n",
        "\n",
        "# Determine if the actual proportion falls within the 95% confidence interval\n",
        "if conf_int[0] <= p2 <= conf_int[1]:\n",
        "    print(\"Actual proportion,\", p2,\", is within the 95% confidence interval\")\n",
        "else:\n",
        "   print(\"Actual proportion,\",p2 ,\", is not within the 95% confidence interval\")"
      ],
      "metadata": {
        "id": "umfPCYU7mG-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-Sample Hypothesis Test for Population Proportions"
      ],
      "metadata": {
        "id": "dbAelbeEmNJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import scipy.stats as st\n",
        "from statsmodels.stats.weightstats import ztest as ztest\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "# Import the correct modules\n",
        "\n",
        "# Read in gpa.csv\n",
        "gpa = pd.read_csv('gpa.csv') # Code to read in data set\n",
        "\n",
        "value = float(input())\n",
        "cutoff = float(input())\n",
        "\n",
        "#print(gpa)\n",
        "#print(gpa[gpa['gpa'] > cutoff])\n",
        "#print(gpa[gpa['gpa'] > cutoff]['gpa'])\n",
        "\n",
        "# Determine the number of students with a gpa higher than cutoff\n",
        "counts = gpa[gpa['gpa'] > cutoff]['gpa'].count() # Code to count number of students with gpa > cutoff\n",
        "\n",
        "# Determine the total number of students\n",
        "nobs = gpa['gpa'].count() # Code to count total number of students\n",
        "\n",
        "#print(counts)\n",
        "#print(nobs)\n",
        "\n",
        "# Perform z-test for counts, nobs, and value\n",
        "ztest = proportions_ztest(counts, nobs, value)  # Code to perform z-test\n",
        "print(ztest)\n",
        "\n",
        "# Determine the correct conclusion\n",
        "if ztest[1] < 0.01: # Finish the if statment\n",
        "    print(\"The two-tailed p-value,\", ztest[1],\", is less than \\u03B1. Thus, sufficient evidence exists to support the hypothesis that the proportion is different from\", value)\n",
        "else:\n",
        "    print(\"The two-tailed p-value,\", ztest[1],\", is greater than than \\u03B1. Thus, insufficient evidence exists to support the hypothesis that the proportion is different from\", value)\n"
      ],
      "metadata": {
        "id": "7zx_RefvmRZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two-Sample T-Test"
      ],
      "metadata": {
        "id": "tIb-HA0QmTUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as st\n",
        "import pandas as pd # Import the necessary modules\n",
        "\n",
        "# Read in the titanic.csv data set\n",
        "titanic = pd.read_csv('titanic.csv') # Code to read in data\n",
        "\n",
        "# Subset the data into male and female\n",
        "male = titanic[titanic.Sex == \"male\"] # Code to subset on Sex = \"male\"\n",
        "female = titanic[titanic.Sex == \"female\"] # Code to subset on Sex = \"female\"\n",
        "\n",
        "# Use the correct t-test to compare values of Fare for both subsets\n",
        "print(st.ttest_ind(male['Fare'],female['Fare']))"
      ],
      "metadata": {
        "id": "_2-vxoKKmV1u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
